{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0635643-b03b-4821-9450-41b04b7ecc84",
   "metadata": {},
   "source": [
    "### Choose model and featureset to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56de4974-bd79-478c-a67b-11d5f4967167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\Model\\DataHelpers.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b644131-76bc-4de4-9ba2-00a97baafbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be replaced with desired variant for different feature sets\n",
    "GENE_FILE_VARIANT = 'lasso'\n",
    "\n",
    "MODEL_VARIANT_SVM = ModelVariant.SVM\n",
    "MODEL_VARIANT_RF = ModelVariant.RF\n",
    "MODEL_VARIANT_LG = ModelVariant.LG\n",
    "\n",
    "FILE_PATH_LG_OUTPUT   = f\"../Data/model_output_lasso_validation_LogisticRegression.csv\"\n",
    "FILE_PATH_RF_OUTPUT   = f\"../Data/model_output_lasso_validation_RandomForestClassifier.csv\"\n",
    "FILE_PATH_SVM_OUTPUT  = f\"../Data/model_output_lasso_validation_SVC.csv\"\n",
    "\n",
    "FILE_PATH_LG_METRICS  = f\"../Data/model_metrics_lasso_validation_LogisticRegression.csv\"\n",
    "FILE_PATH_RF_METRICS  = f\"../Data/model_metrics_lasso_validation_RandomForestClassifier.csv\"\n",
    "FILE_PATH_SVM_METRICS = f\"../Data/model_metrics_lasso_validation_SVC.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ce59a5-888f-4add-8286-649c941f519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "# Output files to load variants for\n",
    "variants = {\n",
    "    \"Random Forest\": FILE_PATH_RF_OUTPUT,\n",
    "    \"Support Vector Machine\": FILE_PATH_SVM_OUTPUT,\n",
    "    \"Logistic Regression\": FILE_PATH_LG_OUTPUT\n",
    "}\n",
    "# Cross-validation metrics files to load variants for\n",
    "variantMetrics = {\n",
    "    \"Random Forest\": FILE_PATH_RF_METRICS,\n",
    "    \"Support Vector Machine\": FILE_PATH_SVM_METRICS,\n",
    "    \"Logistic Regression\": FILE_PATH_LG_METRICS\n",
    "}\n",
    "baseColors = [] # To override the first couple of base colors, add them here (removed because unnecessary)\n",
    "getColors = lambda n: ([ # Lambda to generate as many base colors as needed\n",
    "    to_hex(plt.get_cmap('tab10')((i + len(baseColors)) % plt.get_cmap('tab10').N))\n",
    "    for i in range(max(0, n - len(baseColors)))\n",
    "])[:n]\n",
    "\n",
    "# Definitions\n",
    "evalPrecision = 'precision'\n",
    "evalRecall = 'recall'\n",
    "evalF1score = 'f1-score'\n",
    "\n",
    "evalTargetN = 'nTNBC'\n",
    "evalTarget = 'TNBC'\n",
    "\n",
    "targetNames = [evalTargetN, evalTarget]\n",
    "classLabels = ['Precision', 'Recall', 'F1-score']\n",
    "models = variants.keys()\n",
    "\n",
    "notTNBCData = {}\n",
    "TNBCData = {}\n",
    "accuracyData = {}\n",
    "confusionMatrixes = {}\n",
    "\n",
    "# Read evaluation data for all files\n",
    "for model, file in variants.items():\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    y_test = df['y_validation']\n",
    "    y_pred = df['y_pred']\n",
    "    \n",
    "    classification = classification_report(y_test, y_pred, output_dict=True, target_names=targetNames, zero_division=0)\n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    notTNBCData[model] = (classification[evalTargetN][evalPrecision]*100 , classification[evalTargetN][evalRecall]*100 , classification[evalTargetN][evalF1score]*100 )\n",
    "    TNBCData[model] = (classification[evalTarget][evalPrecision]*100 , classification[evalTarget][evalRecall]*100 , classification[evalTarget][evalF1score]*100 )\n",
    "    accuracyData[model] = accuracy*100\n",
    "    confusionMatrixes[model] = confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5e34e3-0766-474a-af20-0adfce33334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define figure size (flexible to permit more than 3 figures at once, and to decide the number of columns to use)\n",
    "ncols = 3 # Minimum three, for Accuracy, Metrics TNBC, Metrics nTNBC in the first row\n",
    "nrows = ((len(accuracyData) + (ncols - 1)) // ncols) + 1\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, layout='constrained', figsize=[4*ncols, 3*nrows])\n",
    "colors = getColors(len(accuracyData))\n",
    "      \n",
    "# == Accuracy\n",
    "ax[0,0].set_xlim(0,100) \n",
    "rects = ax[0,0].barh(y=accuracyData.keys(), width=accuracyData.values(), color=colors)\n",
    "ax[0,0].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "ax[0,0].set_ylabel('Accuracy (%)', rotation=0, horizontalalignment='left')\n",
    "ax[0,0].yaxis.set_label_coords(-0.37, 0.8)\n",
    "ax[0,0].set_yticklabels('')\n",
    "ax[0,0].invert_yaxis()\n",
    "\n",
    "# == TNBC\n",
    "width = 0.25\n",
    "multiplier = 0\n",
    "ax[0,1].set_xlim(0, 100)\n",
    "y_pos = np.arange(3)\n",
    "for attribute, measurement in TNBCData.items():\n",
    "    offset = width * multiplier\n",
    "    rectsTNBC = ax[0,1].barh(y_pos + offset, measurement, width, label=attribute, color=colors[multiplier])\n",
    "    ax[0,1].bar_label(rectsTNBC, padding=3, fmt='%.2f%%')\n",
    "    multiplier += 1\n",
    "\n",
    "ax[0,1].set_yticks(y_pos)\n",
    "ax[0,1].set_yticklabels(classLabels)\n",
    "ax[0,1].invert_yaxis()\n",
    "ax[0,1].set_xlabel('Metrics TNBC')\n",
    "\n",
    "# == tNBC\n",
    "multiplier = 0\n",
    "ax[0,2].set_xlim(0, 100)\n",
    "y_pos = np.arange(3)\n",
    "for attribute, measurement in notTNBCData.items():\n",
    "    offset = width * multiplier  \n",
    "    rectsNTNBC = ax[0,2].barh(y_pos + offset, measurement, width, label=attribute)\n",
    "    ax[0,2].bar_label(rectsNTNBC, padding=3, fmt='%.2f%%')\n",
    "    multiplier += 1\n",
    "\n",
    "ax[0,2].set_yticks(y_pos)\n",
    "ax[0,2].set_yticklabels(classLabels)\n",
    "ax[0,2].invert_yaxis()\n",
    "ax[0,2].set_xlabel('Metrics nTNBC')\n",
    "\n",
    "# == Confusion matrices\n",
    "# https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "\n",
    "N = 0\n",
    "\n",
    "for model in variants.keys():\n",
    "    x = N % ncols\n",
    "    y = (N // ncols) + 1\n",
    "    ax[y,x].imshow(confusionMatrixes[model], cmap='RdBu_r')\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            text = ax[y,x].text(j, i, confusionMatrixes[model][i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "    \n",
    "    ax[y,x].yaxis.set_visible(False)\n",
    "    ax[y,x].set_xticklabels('')\n",
    "    ax[y,x].set_xlabel(f\"Confusion matrix - {model}\")\n",
    "    ax[y,x].tick_params(axis=u'both', which=u'both',length=0)\n",
    "    N += 1\n",
    "\n",
    "# Hide superfluous axes\n",
    "for i in range(3, ncols):\n",
    "    ax.flat[i].set_visible(False)\n",
    "for i in range(ncols + len(accuracyData), nrows * ncols):\n",
    "    ax.flat[i].set_visible(False)\n",
    "\n",
    "fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "\n",
    "chartsPartOne = plt.gcf()\n",
    "\n",
    "plt.savefig(fname=f\"../Data/lasso_validation_metrics.svg\", format='svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d632ac1e-dc0c-41d1-b29a-047716e371c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "rocAucData = {}\n",
    "fprTprData = {}\n",
    "\n",
    "# Read evaluation data for all files\n",
    "for model, file in variants.items():\n",
    "    dataPath = '../Data'\n",
    "    df = pd.read_csv(os.path.join(dataPath, file))\n",
    "    y_test = df['y_validation']\n",
    "    y_prob = df['y_prob']\n",
    "\n",
    "    fprTprData[model] = roc_curve(y_test, y_prob)\n",
    "    rocAucData[model] = auc(fprTprData[model][0], fprTprData[model][1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429a9d48-fb3e-46fd-a8b9-635e0cbff79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, layout='constrained', figsize=[12,6])\n",
    "\n",
    "## Computing ROC curve [978-14-49-36988-0]\n",
    "\n",
    "\n",
    "for model, fprTpr in fprTprData.items():\n",
    "    ax[0].plot(fprTpr[0], fprTpr[1], label=model)\n",
    "\n",
    "rects = ax[1].barh(y=rocAucData.keys(), width=rocAucData.values(), color=colors)\n",
    "ax[1].set_xlim(0, 100)\n",
    "ax[1].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "ax[1].set_ylabel('AUC score')\n",
    "ax[1].set_yticklabels('')\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "\n",
    "chartsPartTwo = plt.gcf()\n",
    "\n",
    "plt.savefig(fname=f\"../Data/lasso_validation_ROC.svg\", format='svg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78019efa-454b-42ae-b866-bd9687d3281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The actual N-Fold Cross-validation was performed by the model itself (see Model folder). Additional metrics besides accuracy were exported as well\n",
    "\n",
    "nFoldData = {}\n",
    "\n",
    "for model, file in variantMetrics.items():\n",
    "    dataPath = '../Data'\n",
    "    df = pd.read_csv(os.path.join(dataPath, file))\n",
    "    cs_scores = df['accuracy']\n",
    "    nFoldData[model] = cs_scores.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c433b912-f3f6-4589-ac33-6453ece1d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects = ax.bar(nFoldData.keys(), nFoldData.values(), label=nFoldData.keys(), color=getColors(len(nFoldData)))\n",
    "ax.bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "\n",
    "plt.savefig(fname=f\"../Data/lasso_validation_5fold.svg\", format='svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd5396-2d73-4210-aba7-42dc2fe79b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff6f60-2b51-4d15-a36d-dcdd481f56fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85e72a-29ed-4996-a29c-e7c62aee7d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716701b-aba5-4225-9348-777afdd09c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd086e-2481-4c60-ba46-5d95a13fe213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333fc416-3c85-438b-b16a-9eff864138bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63686b-0d75-452b-bff9-2c9fc3ffff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d26eae-f095-4a85-8264-cf6b7c7a25ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad478fe-4b5c-4369-ad96-bb3afd5a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteStati = ['SMOTE', 'nSMOTE']\n",
    "total = len(FeatureVariant)*len(smoteStati)\n",
    "counter = 1\n",
    "\n",
    "    print(f\"{counter}/{total} - FeatureSet {GENE_FILE_VARIANT} - Start\")\n",
    "\n",
    "    #======================================\n",
    "    # Get Metrics and Output of Models from Files\n",
    "    #======================================\n",
    "    MODEL_VARIANT_SVM = 'SVM' # For values, see ModelVariant.print_info()\n",
    "    MODEL_VARIANT_RF  = 'RF'  # For values, see ModelVariant.print_info()\n",
    "    MODEL_VARIANT_LG  = 'LG'  # For values, see ModelVariant.print_info()\n",
    "\n",
    "    if 'nSMOTE' == smote:\n",
    "        FILE_PATH_LG_OUTPUT  = f\"../Data/model_output_{MODEL_VARIANT_LG}_{GENE_FILE_VARIANT}.csv\"\n",
    "        FILE_PATH_RF_OUTPUT  = f\"../Data/model_output_{MODEL_VARIANT_RF}_{GENE_FILE_VARIANT}.csv\"\n",
    "        FILE_PATH_SVM_OUTPUT = f\"../Data/model_output_{MODEL_VARIANT_SVM}_{GENE_FILE_VARIANT}.csv\"\n",
    "        \n",
    "        FILE_PATH_LG_METRICS  = f\"../Data/model_metrics_{MODEL_VARIANT_LG}_{GENE_FILE_VARIANT}.csv\"\n",
    "        FILE_PATH_RF_METRICS  = f\"../Data/model_metrics_{MODEL_VARIANT_RF}_{GENE_FILE_VARIANT}.csv\"\n",
    "        FILE_PATH_SVM_METRICS = f\"../Data/model_metrics_{MODEL_VARIANT_SVM}_{GENE_FILE_VARIANT}.csv\"\n",
    "\n",
    "    #======================================\n",
    "    # Process data of Files into Dictionary\n",
    "    #======================================\n",
    "    # Output files to load variants for\n",
    "    variants = {\n",
    "        \"Random Forest\": FILE_PATH_RF_OUTPUT,\n",
    "        \"Support Vector Machine\": FILE_PATH_SVM_OUTPUT,\n",
    "        \"Logistic Regression\": FILE_PATH_LG_OUTPUT,\n",
    "        # Adding more is possible but might need layout tweaks for readability\n",
    "    }\n",
    "    # Cross-validation metrics files to load variants for\n",
    "    variantMetrics = {\n",
    "        \"Random Forest\": FILE_PATH_RF_METRICS,\n",
    "        \"Support Vector Machine\": FILE_PATH_SVM_METRICS,\n",
    "        \"Logistic Regression\": FILE_PATH_LG_METRICS,\n",
    "        # Adding more is possible but might need layout tweaks for readability\n",
    "    }\n",
    "    baseColors = [] # To override the first couple of base colors, add them here (removed because unnecessary)\n",
    "    getColors = lambda n: ([ # Lambda to generate as many base colors as needed\n",
    "        to_hex(plt.get_cmap('tab10')((i + len(baseColors)) % plt.get_cmap('tab10').N))\n",
    "        for i in range(max(0, n - len(baseColors)))\n",
    "    ])[:n]\n",
    "    \n",
    "    # Definitions\n",
    "    evalPrecision = 'precision'\n",
    "    evalRecall = 'recall'\n",
    "    evalF1score = 'f1-score'\n",
    "    \n",
    "    evalTargetN = 'nTNBC'\n",
    "    evalTarget = 'TNBC'\n",
    "    \n",
    "    targetNames = [evalTargetN, evalTarget]\n",
    "    classLabels = ['Precision', 'Recall', 'F1-score']\n",
    "    models = variants.keys()\n",
    "    \n",
    "    notTNBCData = {}\n",
    "    TNBCData = {}\n",
    "    accuracyData = {}\n",
    "    confusionMatrixes = {}\n",
    "    \n",
    "    # Read evaluation data for all files\n",
    "    for model, file in variants.items():\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        y_test = df['y_test']\n",
    "        y_pred = df['y_pred']\n",
    "        \n",
    "        classification = classification_report(y_test, y_pred, output_dict=True, target_names=targetNames, zero_division=0)\n",
    "        confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "        notTNBCData[model] = (classification[evalTargetN][evalPrecision]*100 , classification[evalTargetN][evalRecall]*100 , classification[evalTargetN][evalF1score]*100 )\n",
    "        TNBCData[model] = (classification[evalTarget][evalPrecision]*100 , classification[evalTarget][evalRecall]*100 , classification[evalTarget][evalF1score]*100 )\n",
    "        accuracyData[model] = accuracy*100\n",
    "        confusionMatrixes[model] = confusionMatrix\n",
    "\n",
    "    #======================================\n",
    "    # Generate charts of Metrics and Output\n",
    "    #======================================\n",
    "    # Define figure size (flexible to permit more than 3 figures at once, and to decide the number of columns to use)\n",
    "    ncols = 3 # Minimum three, for Accuracy, Metrics TNBC, Metrics nTNBC in the first row\n",
    "    nrows = ((len(accuracyData) + (ncols - 1)) // ncols) + 1\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, layout='constrained', figsize=[4*ncols, 3*nrows])\n",
    "    colors = getColors(len(accuracyData))\n",
    "          \n",
    "    # == Accuracy\n",
    "    ax[0,0].set_xlim(0,100) \n",
    "    rects = ax[0,0].barh(y=accuracyData.keys(), width=accuracyData.values(), color=colors)\n",
    "    ax[0,0].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "    ax[0,0].set_ylabel('Accuracy (%)', rotation=0, horizontalalignment='left')\n",
    "    ax[0,0].yaxis.set_label_coords(-0.37, 0.8)\n",
    "    ax[0,0].set_yticklabels('')\n",
    "    ax[0,0].invert_yaxis()\n",
    "    \n",
    "    # == TNBC\n",
    "    width = 0.25\n",
    "    multiplier = 0\n",
    "    ax[0,1].set_xlim(0, 100)\n",
    "    y_pos = np.arange(3)\n",
    "    for attribute, measurement in TNBCData.items():\n",
    "        offset = width * multiplier\n",
    "        rectsTNBC = ax[0,1].barh(y_pos + offset, measurement, width, label=attribute, color=colors[multiplier])\n",
    "        ax[0,1].bar_label(rectsTNBC, padding=3, fmt='%.2f%%')\n",
    "        multiplier += 1\n",
    "    \n",
    "    ax[0,1].set_yticks(y_pos)\n",
    "    ax[0,1].set_yticklabels(classLabels)\n",
    "    ax[0,1].invert_yaxis()\n",
    "    ax[0,1].set_xlabel('Metrics TNBC')\n",
    "    \n",
    "    # == tNBC\n",
    "    multiplier = 0\n",
    "    ax[0,2].set_xlim(0, 100)\n",
    "    y_pos = np.arange(3)\n",
    "    for attribute, measurement in notTNBCData.items():\n",
    "        offset = width * multiplier  \n",
    "        rectsNTNBC = ax[0,2].barh(y_pos + offset, measurement, width, label=attribute)\n",
    "        ax[0,2].bar_label(rectsNTNBC, padding=3, fmt='%.2f%%')\n",
    "        multiplier += 1\n",
    "    \n",
    "    ax[0,2].set_yticks(y_pos)\n",
    "    ax[0,2].set_yticklabels(classLabels)\n",
    "    ax[0,2].invert_yaxis()\n",
    "    ax[0,2].set_xlabel('Metrics nTNBC')\n",
    "    \n",
    "    # == Confusion matrices\n",
    "    # https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    \n",
    "    N = 0\n",
    "    \n",
    "    for model in variants.keys():\n",
    "        x = N % ncols\n",
    "        y = (N // ncols) + 1\n",
    "        ax[y,x].imshow(confusionMatrixes[model], cmap='RdBu_r')\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                text = ax[y,x].text(j, i, confusionMatrixes[model][i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "        \n",
    "        ax[y,x].yaxis.set_visible(False)\n",
    "        ax[y,x].set_xticklabels('')\n",
    "        ax[y,x].set_xlabel(f\"Confusion matrix - {model}\")\n",
    "        ax[y,x].tick_params(axis=u'both', which=u'both',length=0)\n",
    "        N += 1\n",
    "    \n",
    "    # Hide superfluous axes\n",
    "    for i in range(3, ncols):\n",
    "        ax.flat[i].set_visible(False)\n",
    "    for i in range(ncols + len(accuracyData), nrows * ncols):\n",
    "        ax.flat[i].set_visible(False)\n",
    "    \n",
    "    fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "    \n",
    "    chartsPartOne = plt.gcf()\n",
    "\n",
    "    if 'nSMOTE' == smote:\n",
    "        plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_metrics.svg\", format='svg')\n",
    "    else:\n",
    "        plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_metrics_smote.svg\", format='svg')\n",
    "        \n",
    "    plt.close()\n",
    "\n",
    "    #======================================\n",
    "    # Get ROC data\n",
    "    #======================================\n",
    "    rocAucData = {}\n",
    "    fprTprData = {}\n",
    "    \n",
    "    # Read evaluation data for all files\n",
    "    for model, file in variants.items():\n",
    "        dataPath = '../Data'\n",
    "        df = pd.read_csv(os.path.join(dataPath, file))\n",
    "        y_test = df['y_test']\n",
    "        y_prob = df['y_prob']\n",
    "    \n",
    "        fprTprData[model] = roc_curve(y_test, y_prob)\n",
    "        rocAucData[model] = auc(fprTprData[model][0], fprTprData[model][1]) * 100\n",
    "\n",
    "    #======================================\n",
    "    # Generate Chart of ROC data\n",
    "    #======================================\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, layout='constrained', figsize=[12,6])\n",
    "    \n",
    "    ## Computing ROC curve [ISBN 978-14-49-36988-0]\n",
    "    for model, fprTpr in fprTprData.items():\n",
    "        ax[0].plot(fprTpr[0], fprTpr[1], label=model)\n",
    "    \n",
    "    rects = ax[1].barh(y=rocAucData.keys(), width=rocAucData.values(), color=colors)\n",
    "    ax[1].set_xlim(0, 100)\n",
    "    ax[1].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "    ax[1].set_ylabel('AUC score')\n",
    "    ax[1].set_yticklabels('')\n",
    "    ax[1].invert_yaxis()\n",
    "    \n",
    "    fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "    \n",
    "    chartsPartTwo = plt.gcf()\n",
    "\n",
    "    if 'nSMOTE' == smote:\n",
    "        plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_ROC.svg\", format='svg')\n",
    "    else:\n",
    "        plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_ROC_smote.svg\", format='svg')\n",
    "        \n",
    "    plt.close()\n",
    "\n",
    "    #======================================\n",
    "    # Get 5 Fold data\n",
    "    #======================================\n",
    "    nFoldData = {}\n",
    "    \n",
    "    for model, file in variantMetrics.items():\n",
    "        dataPath = '../Data'\n",
    "        df = pd.read_csv(os.path.join(dataPath, file))\n",
    "        cs_scores = df['accuracy']\n",
    "        nFoldData[model] = cs_scores.mean() * 100\n",
    "\n",
    "    #======================================\n",
    "    # Generate chart of 5 Fold data\n",
    "    #======================================\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    rects = ax.bar(nFoldData.keys(), nFoldData.values(), label=nFoldData.keys(), color=getColors(len(nFoldData)))\n",
    "    ax.bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "\n",
    "    if 'nSMOTE' == smote:\n",
    "        plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_5fold.svg\", format='svg')\n",
    "    else:\n",
    "        plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_5fold_smote.svg\", format='svg')\n",
    "        \n",
    "    plt.close()\n",
    "\n",
    "    print(f\"{counter}/{total} - FeatureSet {GENE_FILE_VARIANT} - {smote} - End\")\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba0715-c28b-4a63-aebb-94feb4ad5812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c9dce-e21e-46a7-b97c-a496df5b2b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a67e62-be01-42b5-90d3-a195a071596b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301e275-c9bd-4e4b-a571-22fefb846391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ede2af-52d2-42db-b417-71b00c45e915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8a077-5045-4202-8435-6f31787a9bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e7f9b-3720-4c4c-ac54-1c5d9aff75bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffe576-587e-48a6-a032-b8d0c9408ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1095a-f4d6-47f6-b4b4-66cefa6f2693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c17b0-18e4-4532-b272-1f25766cba3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2708cc-3639-49d2-b5de-3683cc0645c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c936d855-8df3-4cab-8db6-d7945fce7779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed92b35-05ff-4ec7-8c82-976ed02b099d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d841b5-d1c6-40ef-bb5e-0c9e924d16ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d774dd6-eb08-4ab2-889d-47ca01fcc4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be replaced with desired variant for different feature sets\n",
    "GENE_FILE_VARIANT = 'lasso' # For values, see FeatureVariant.print_info()\n",
    "\n",
    "MODEL_VARIANT_SVM = ModelVariant.SVM # For values, see ModelVariant.print_info()\n",
    "MODEL_VARIANT_RF = ModelVariant.RF # For values, see ModelVariant.print_info()\n",
    "MODEL_VARIANT_LG = ModelVariant.LG # For values, see ModelVariant.print_info()\n",
    "\n",
    "#FILE_PATH_LG_OUTPUT = f\"../Data/model_output_{MODEL_VARIANT_LG}_{GENE_FILE_VARIANT}.csv\"\n",
    "#FILE_PATH_RF_OUTPUT = f\"../Data/model_output_{MODEL_VARIANT_RF}_{GENE_FILE_VARIANT}.csv\"\n",
    "FILE_PATH_SVM_OUTPUT = f\"../Data/model_output_lasso_validation.csv\"\n",
    "\n",
    "# FILE_PATH_LG_METRICS = f\"../Data/model_metrics_{MODEL_VARIANT_LG}_{GENE_FILE_VARIANT}.csv\"\n",
    "# FILE_PATH_RF_METRICS = f\"../Data/model_metrics_{MODEL_VARIANT_RF}_{GENE_FILE_VARIANT}.csv\"\n",
    "FILE_PATH_SVM_METRICS = f\"../Data/model_metrics_lasso_validation.csv\"\n",
    "\n",
    "# print(FILE_PATH_LG_METRICS)\n",
    "# print(FILE_PATH_RF_METRICS)\n",
    "# print(FILE_PATH_SVM_METRICS)\n",
    "\n",
    "# print(FILE_PATH_LG_OUTPUT)\n",
    "# print(FILE_PATH_RF_OUTPUT)\n",
    "# print(FILE_PATH_SVM_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "693d0ea0-a78e-49be-bb48-2aa57f9dc680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>y_validation</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM1588972</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM1588973</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.015147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM1588981</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM1588989</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM1588990</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>GSM1589035</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.213807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>GSM1589036</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.255012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>GSM1589037</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.302368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>GSM1589038</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>GSM1589039</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.198699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_id  y_validation  y_pred    y_prob\n",
       "0    GSM1588972         False   False  0.008212\n",
       "1    GSM1588973         False   False  0.015147\n",
       "2    GSM1588981         False   False  0.008630\n",
       "3    GSM1588989         False   False  0.006797\n",
       "4    GSM1588990         False   False  0.008316\n",
       "..          ...           ...     ...       ...\n",
       "122  GSM1589035          True   False  0.213807\n",
       "123  GSM1589036          True   False  0.255012\n",
       "124  GSM1589037          True   False  0.302368\n",
       "125  GSM1589038          True   False  0.170800\n",
       "126  GSM1589039          True   False  0.198699\n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(FILE_PATH_SVM_OUTPUT)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15765e-443d-4b03-b238-a2249b4e5584",
   "metadata": {},
   "source": [
    "### Get Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c740f236-c27e-4d4e-a3b8-0646c95a5c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support Vector Machine': (100.0, 26.666666666666668, 42.10526315789473)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "# Output files to load variants for\n",
    "variants = {\n",
    "    #\"Random Forest\": FILE_PATH_RF_OUTPUT,\n",
    "    \"Support Vector Machine\": FILE_PATH_SVM_OUTPUT\n",
    "    #\"Logistic Regression\": FILE_PATH_LG_OUTPUT,\n",
    "    # Adding more is possible but might need layout tweaks for readability\n",
    "}\n",
    "# Cross-validation metrics files to load variants for\n",
    "variantMetrics = {\n",
    "    #\"Random Forest\": FILE_PATH_RF_METRICS,\n",
    "    \"Support Vector Machine\": FILE_PATH_SVM_METRICS\n",
    "    #\"Logistic Regression\": FILE_PATH_LG_METRICS,\n",
    "    # Adding more is possible but might need layout tweaks for readability\n",
    "}\n",
    "baseColors = [] # To override the first couple of base colors, add them here (removed because unnecessary)\n",
    "getColors = lambda n: ([ # Lambda to generate as many base colors as needed\n",
    "    to_hex(plt.get_cmap('tab10')((i + len(baseColors)) % plt.get_cmap('tab10').N))\n",
    "    for i in range(max(0, n - len(baseColors)))\n",
    "])[:n]\n",
    "\n",
    "# Definitions\n",
    "evalPrecision = 'precision'\n",
    "evalRecall = 'recall'\n",
    "evalF1score = 'f1-score'\n",
    "\n",
    "evalTargetN = 'nTNBC'\n",
    "evalTarget = 'TNBC'\n",
    "\n",
    "targetNames = [evalTargetN, evalTarget]\n",
    "classLabels = ['Precision', 'Recall', 'F1-score']\n",
    "models = variants.keys()\n",
    "\n",
    "notTNBCData = {}\n",
    "TNBCData = {}\n",
    "accuracyData = {}\n",
    "confusionMatrixes = {}\n",
    "\n",
    "# Read evaluation data for all files\n",
    "for model, file in variants.items():\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    y_test = df['y_validation']\n",
    "    y_pred = df['y_pred']\n",
    "    \n",
    "    classification = classification_report(y_test, y_pred, output_dict=True, target_names=targetNames, zero_division=0)\n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    notTNBCData[model] = (classification[evalTargetN][evalPrecision]*100 , classification[evalTargetN][evalRecall]*100 , classification[evalTargetN][evalF1score]*100 )\n",
    "    TNBCData[model] = (classification[evalTarget][evalPrecision]*100 , classification[evalTarget][evalRecall]*100 , classification[evalTarget][evalF1score]*100 )\n",
    "    accuracyData[model] = accuracy*100\n",
    "    confusionMatrixes[model] = confusionMatrix\n",
    "\n",
    "TNBCData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c810e-1c98-4baa-8df7-f51196dc2f28",
   "metadata": {},
   "source": [
    "### Plot the data to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704ea024-3fa1-4bdd-b387-258e9658d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define figure size (flexible to permit more than 3 figures at once, and to decide the number of columns to use)\n",
    "ncols = 3 # Minimum three, for Accuracy, Metrics TNBC, Metrics nTNBC in the first row\n",
    "nrows = ((len(accuracyData) + (ncols - 1)) // ncols) + 1\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, layout='constrained', figsize=[4*ncols, 3*nrows])\n",
    "colors = getColors(len(accuracyData))\n",
    "      \n",
    "# == Accuracy\n",
    "ax[0,0].set_xlim(0,100) \n",
    "rects = ax[0,0].barh(y=accuracyData.keys(), width=accuracyData.values(), color=colors)\n",
    "ax[0,0].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "ax[0,0].set_ylabel('Accuracy (%)', rotation=0, horizontalalignment='left')\n",
    "ax[0,0].yaxis.set_label_coords(-0.37, 0.8)\n",
    "ax[0,0].set_yticklabels('')\n",
    "ax[0,0].invert_yaxis()\n",
    "\n",
    "# == TNBC\n",
    "width = 0.25\n",
    "multiplier = 0\n",
    "ax[0,1].set_xlim(0, 100)\n",
    "y_pos = np.arange(3)\n",
    "for attribute, measurement in TNBCData.items():\n",
    "    offset = width * multiplier\n",
    "    rectsTNBC = ax[0,1].barh(y_pos + offset, measurement, width, label=attribute, color=colors[multiplier])\n",
    "    ax[0,1].bar_label(rectsTNBC, padding=3, fmt='%.2f%%')\n",
    "    multiplier += 1\n",
    "\n",
    "ax[0,1].set_yticks(y_pos)\n",
    "ax[0,1].set_yticklabels(classLabels)\n",
    "ax[0,1].invert_yaxis()\n",
    "ax[0,1].set_xlabel('Metrics TNBC')\n",
    "\n",
    "# == tNBC\n",
    "multiplier = 0\n",
    "ax[0,2].set_xlim(0, 100)\n",
    "y_pos = np.arange(3)\n",
    "for attribute, measurement in notTNBCData.items():\n",
    "    offset = width * multiplier  \n",
    "    rectsNTNBC = ax[0,2].barh(y_pos + offset, measurement, width, label=attribute)\n",
    "    ax[0,2].bar_label(rectsNTNBC, padding=3, fmt='%.2f%%')\n",
    "    multiplier += 1\n",
    "\n",
    "ax[0,2].set_yticks(y_pos)\n",
    "ax[0,2].set_yticklabels(classLabels)\n",
    "ax[0,2].invert_yaxis()\n",
    "ax[0,2].set_xlabel('Metrics nTNBC')\n",
    "\n",
    "# == Confusion matrices\n",
    "# https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "\n",
    "N = 0\n",
    "\n",
    "for model in variants.keys():\n",
    "    x = N % ncols\n",
    "    y = (N // ncols) + 1\n",
    "    ax[y,x].imshow(confusionMatrixes[model], cmap='RdBu_r')\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            text = ax[y,x].text(j, i, confusionMatrixes[model][i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "    \n",
    "    ax[y,x].yaxis.set_visible(False)\n",
    "    ax[y,x].set_xticklabels('')\n",
    "    ax[y,x].set_xlabel(f\"Confusion matrix - {model}\")\n",
    "    ax[y,x].tick_params(axis=u'both', which=u'both',length=0)\n",
    "    N += 1\n",
    "\n",
    "# Hide superfluous axes\n",
    "for i in range(3, ncols):\n",
    "    ax.flat[i].set_visible(False)\n",
    "for i in range(ncols + len(accuracyData), nrows * ncols):\n",
    "    ax.flat[i].set_visible(False)\n",
    "\n",
    "fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "\n",
    "chartsPartOne = plt.gcf()\n",
    "\n",
    "plt.savefig(fname=f\"../Data/lasso_validation_metrics.svg\", format='svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef894e47-6b2d-432e-b104-dec9ba7aea07",
   "metadata": {},
   "source": [
    "### Plot the ROC Curve and Compute AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbda285f-5007-451e-b5ca-4b96247f37a9",
   "metadata": {},
   "source": [
    "#### Get the ROC and AUC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49f65327-07f9-46df-a65a-81e34cc8ebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support Vector Machine': 98.63095238095238}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "rocAucData = {}\n",
    "fprTprData = {}\n",
    "\n",
    "# Read evaluation data for all files\n",
    "for model, file in variants.items():\n",
    "    dataPath = '../Data'\n",
    "    df = pd.read_csv(os.path.join(dataPath, file))\n",
    "    y_test = df['y_validation']\n",
    "    y_prob = df['y_prob']\n",
    "\n",
    "    fprTprData[model] = roc_curve(y_test, y_prob)\n",
    "    rocAucData[model] = auc(fprTprData[model][0], fprTprData[model][1]) * 100\n",
    "\n",
    "rocAucData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71364fb6-46d4-4ebb-a2d2-5bf51ea4f9f7",
   "metadata": {},
   "source": [
    "#### Plot the data to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d94919c0-8f3e-434c-9413-c5fb3cff3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, layout='constrained', figsize=[12,6])\n",
    "\n",
    "## Computing ROC curve [978-14-49-36988-0]\n",
    "\n",
    "\n",
    "for model, fprTpr in fprTprData.items():\n",
    "    ax[0].plot(fprTpr[0], fprTpr[1], label=model)\n",
    "\n",
    "rects = ax[1].barh(y=rocAucData.keys(), width=rocAucData.values(), color=colors)\n",
    "ax[1].set_xlim(0, 100)\n",
    "ax[1].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "ax[1].set_ylabel('AUC score')\n",
    "ax[1].set_yticklabels('')\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "\n",
    "chartsPartTwo = plt.gcf()\n",
    "\n",
    "plt.savefig(fname=f\"../Data/lasso_validation_ROC.svg\", format='svg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a9067-6d6a-405c-a0bf-e57a0a24d1a6",
   "metadata": {},
   "source": [
    "### Cross Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116bfb6-9662-4989-b245-9b49d60af9f1",
   "metadata": {},
   "source": [
    "#### Get 5-Fold Cross Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "212fc616-f3e3-4631-908c-35a08afd4a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support Vector Machine': 94.462587780923}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: The actual N-Fold Cross-validation was performed by the model itself (see Model folder). Additional metrics besides accuracy were exported as well\n",
    "\n",
    "nFoldData = {}\n",
    "\n",
    "for model, file in variantMetrics.items():\n",
    "    dataPath = '../Data'\n",
    "    df = pd.read_csv(os.path.join(dataPath, file))\n",
    "    cs_scores = df['accuracy']\n",
    "    nFoldData[model] = cs_scores.mean() * 100\n",
    "\n",
    "nFoldData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945899fc-a305-4527-af25-4decc6a0ca87",
   "metadata": {},
   "source": [
    "#### Plot data to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b73c3ec9-2b18-4177-93b4-0df05623596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects = ax.bar(nFoldData.keys(), nFoldData.values(), label=nFoldData.keys(), color=getColors(len(nFoldData)))\n",
    "ax.bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "\n",
    "plt.savefig(fname=f\"../Data/lasso_validation_5fold.svg\", format='svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fb4c3-7c0f-4076-8e07-6bc5f6d47f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
