{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0635643-b03b-4821-9450-41b04b7ecc84",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56de4974-bd79-478c-a67b-11d5f4967167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"..\\Model\\DataHelpers.ipynb\"\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b7f2d-6e58-4d81-a3b0-4da86fb603de",
   "metadata": {},
   "source": [
    "# Run Evaluation for all feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce1da49-34d2-426c-bdb0-d594fe96181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 - FeatureSet researchpapers - Start\n",
      "1/7 - FeatureSet researchpapers - End\n",
      "2/7 - FeatureSet boruta - Start\n",
      "2/7 - FeatureSet boruta - End\n",
      "3/7 - FeatureSet rfe - Start\n",
      "3/7 - FeatureSet rfe - End\n",
      "4/7 - FeatureSet lasso - Start\n",
      "4/7 - FeatureSet lasso - End\n",
      "5/7 - FeatureSet literature - Start\n",
      "5/7 - FeatureSet literature - End\n",
      "6/7 - FeatureSet statistical - Start\n",
      "6/7 - FeatureSet statistical - End\n",
      "7/7 - FeatureSet automated - SKIPPED ***\n"
     ]
    }
   ],
   "source": [
    "total = len(FeatureVariant)\n",
    "counter = 1\n",
    "\n",
    "for GENE_FILE_VARIANT in FeatureVariant:\n",
    "    if GENE_FILE_VARIANT == 'automated':\n",
    "        print(f\"{counter}/{total} - FeatureSet {GENE_FILE_VARIANT} - SKIPPED ***\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"{counter}/{total} - FeatureSet {GENE_FILE_VARIANT} - Start\")\n",
    "\n",
    "    #======================================\n",
    "    # Get Metrics and Output of Models from Files\n",
    "    #======================================\n",
    "    MODEL_VARIANT_SVM = 'SVM' # For values, see ModelVariant.print_info()\n",
    "    MODEL_VARIANT_RF  = 'RF'  # For values, see ModelVariant.print_info()\n",
    "    MODEL_VARIANT_LG  = 'LG'  # For values, see ModelVariant.print_info()\n",
    "    \n",
    "    FILE_PATH_LG_OUTPUT  = f\"../Data/model_output_{MODEL_VARIANT_LG}_{GENE_FILE_VARIANT}.csv\"\n",
    "    FILE_PATH_RF_OUTPUT  = f\"../Data/model_output_{MODEL_VARIANT_RF}_{GENE_FILE_VARIANT}.csv\"\n",
    "    FILE_PATH_SVM_OUTPUT = f\"../Data/model_output_{MODEL_VARIANT_SVM}_{GENE_FILE_VARIANT}.csv\"\n",
    "    \n",
    "    FILE_PATH_LG_METRICS  = f\"../Data/model_metrics_{MODEL_VARIANT_LG}_{GENE_FILE_VARIANT}.csv\"\n",
    "    FILE_PATH_RF_METRICS  = f\"../Data/model_metrics_{MODEL_VARIANT_RF}_{GENE_FILE_VARIANT}.csv\"\n",
    "    FILE_PATH_SVM_METRICS = f\"../Data/model_metrics_{MODEL_VARIANT_SVM}_{GENE_FILE_VARIANT}.csv\"\n",
    "\n",
    "    #======================================\n",
    "    # Process data of Files into Dictionary\n",
    "    #======================================\n",
    "    # Output files to load variants for\n",
    "    variants = {\n",
    "        \"Random Forest\": FILE_PATH_RF_OUTPUT,\n",
    "        \"Support Vector Machine\": FILE_PATH_SVM_OUTPUT,\n",
    "        \"Logistic Regression\": FILE_PATH_LG_OUTPUT,\n",
    "        # Adding more is possible but might need layout tweaks for readability\n",
    "    }\n",
    "    # Cross-validation metrics files to load variants for\n",
    "    variantMetrics = {\n",
    "        \"Random Forest\": FILE_PATH_RF_METRICS,\n",
    "        \"Support Vector Machine\": FILE_PATH_SVM_METRICS,\n",
    "        \"Logistic Regression\": FILE_PATH_LG_METRICS,\n",
    "        # Adding more is possible but might need layout tweaks for readability\n",
    "    }\n",
    "    baseColors = [] # To override the first couple of base colors, add them here (removed because unnecessary)\n",
    "    getColors = lambda n: ([ # Lambda to generate as many base colors as needed\n",
    "        to_hex(plt.get_cmap('tab10')((i + len(baseColors)) % plt.get_cmap('tab10').N))\n",
    "        for i in range(max(0, n - len(baseColors)))\n",
    "    ])[:n]\n",
    "    \n",
    "    # Definitions\n",
    "    evalPrecision = 'precision'\n",
    "    evalRecall = 'recall'\n",
    "    evalF1score = 'f1-score'\n",
    "    \n",
    "    evalTargetN = 'nTNBC'\n",
    "    evalTarget = 'TNBC'\n",
    "    \n",
    "    targetNames = [evalTargetN, evalTarget]\n",
    "    classLabels = ['Precision', 'Recall', 'F1-score']\n",
    "    models = variants.keys()\n",
    "    \n",
    "    notTNBCData = {}\n",
    "    TNBCData = {}\n",
    "    accuracyData = {}\n",
    "    confusionMatrixes = {}\n",
    "    \n",
    "    # Read evaluation data for all files\n",
    "    for model, file in variants.items():\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        y_test = df['y_test']\n",
    "        y_pred = df['y_pred']\n",
    "        \n",
    "        classification = classification_report(y_test, y_pred, output_dict=True, target_names=targetNames, zero_division=0)\n",
    "        confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "        notTNBCData[model] = (classification[evalTargetN][evalPrecision]*100 , classification[evalTargetN][evalRecall]*100 , classification[evalTargetN][evalF1score]*100 )\n",
    "        TNBCData[model] = (classification[evalTarget][evalPrecision]*100 , classification[evalTarget][evalRecall]*100 , classification[evalTarget][evalF1score]*100 )\n",
    "        accuracyData[model] = accuracy*100\n",
    "        confusionMatrixes[model] = confusionMatrix\n",
    "\n",
    "    #======================================\n",
    "    # Generate charts of Metrics and Output\n",
    "    #======================================\n",
    "    # Define figure size (flexible to permit more than 3 figures at once, and to decide the number of columns to use)\n",
    "    ncols = 3 # Minimum three, for Accuracy, Metrics TNBC, Metrics nTNBC in the first row\n",
    "    nrows = ((len(accuracyData) + (ncols - 1)) // ncols) + 1\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, layout='constrained', figsize=[4*ncols, 3*nrows])\n",
    "    colors = getColors(len(accuracyData))\n",
    "          \n",
    "    # == Accuracy\n",
    "    ax[0,0].set_xlim(0,100) \n",
    "    rects = ax[0,0].barh(y=accuracyData.keys(), width=accuracyData.values(), color=colors)\n",
    "    ax[0,0].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "    ax[0,0].set_ylabel('Accuracy (%)', rotation=0, horizontalalignment='left')\n",
    "    ax[0,0].yaxis.set_label_coords(-0.37, 0.8)\n",
    "    ax[0,0].set_yticklabels('')\n",
    "    ax[0,0].invert_yaxis()\n",
    "    \n",
    "    # == TNBC\n",
    "    width = 0.25\n",
    "    multiplier = 0\n",
    "    ax[0,1].set_xlim(0, 100)\n",
    "    y_pos = np.arange(3)\n",
    "    for attribute, measurement in TNBCData.items():\n",
    "        offset = width * multiplier\n",
    "        rectsTNBC = ax[0,1].barh(y_pos + offset, measurement, width, label=attribute, color=colors[multiplier])\n",
    "        ax[0,1].bar_label(rectsTNBC, padding=3, fmt='%.2f%%')\n",
    "        multiplier += 1\n",
    "    \n",
    "    ax[0,1].set_yticks(y_pos)\n",
    "    ax[0,1].set_yticklabels(classLabels)\n",
    "    ax[0,1].invert_yaxis()\n",
    "    ax[0,1].set_xlabel('Metrics TNBC')\n",
    "    \n",
    "    # == tNBC\n",
    "    multiplier = 0\n",
    "    ax[0,2].set_xlim(0, 100)\n",
    "    y_pos = np.arange(3)\n",
    "    for attribute, measurement in notTNBCData.items():\n",
    "        offset = width * multiplier  \n",
    "        rectsNTNBC = ax[0,2].barh(y_pos + offset, measurement, width, label=attribute)\n",
    "        ax[0,2].bar_label(rectsNTNBC, padding=3, fmt='%.2f%%')\n",
    "        multiplier += 1\n",
    "    \n",
    "    ax[0,2].set_yticks(y_pos)\n",
    "    ax[0,2].set_yticklabels(classLabels)\n",
    "    ax[0,2].invert_yaxis()\n",
    "    ax[0,2].set_xlabel('Metrics nTNBC')\n",
    "    \n",
    "    # == Confusion matrices\n",
    "    # https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    \n",
    "    N = 0\n",
    "    \n",
    "    for model in variants.keys():\n",
    "        x = N % ncols\n",
    "        y = (N // ncols) + 1\n",
    "        ax[y,x].imshow(confusionMatrixes[model], cmap='RdBu_r')\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                text = ax[y,x].text(j, i, confusionMatrixes[model][i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "        \n",
    "        ax[y,x].yaxis.set_visible(False)\n",
    "        ax[y,x].set_xticklabels('')\n",
    "        ax[y,x].set_xlabel(f\"Confusion matrix - {model}\")\n",
    "        ax[y,x].tick_params(axis=u'both', which=u'both',length=0)\n",
    "        N += 1\n",
    "    \n",
    "    # Hide superfluous axes\n",
    "    for i in range(3, ncols):\n",
    "        ax.flat[i].set_visible(False)\n",
    "    for i in range(ncols + len(accuracyData), nrows * ncols):\n",
    "        ax.flat[i].set_visible(False)\n",
    "    \n",
    "    fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "    \n",
    "    chartsPartOne = plt.gcf()\n",
    "    \n",
    "    plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_metrics.svg\", format='svg')\n",
    "    plt.close()\n",
    "\n",
    "    #======================================\n",
    "    # Get ROC data\n",
    "    #======================================\n",
    "    rocAucData = {}\n",
    "    fprTprData = {}\n",
    "    \n",
    "    # Read evaluation data for all files\n",
    "    for model, file in variants.items():\n",
    "        dataPath = '../Data'\n",
    "        df = pd.read_csv(os.path.join(dataPath, file))\n",
    "        y_test = df['y_test']\n",
    "        y_prob = df['y_prob']\n",
    "    \n",
    "        fprTprData[model] = roc_curve(y_test, y_prob)\n",
    "        rocAucData[model] = auc(fprTprData[model][0], fprTprData[model][1]) * 100\n",
    "\n",
    "    #======================================\n",
    "    # Generate Chart of ROC data\n",
    "    #======================================\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, layout='constrained', figsize=[12,6])\n",
    "    \n",
    "    ## Computing ROC curve [ISBN 978-14-49-36988-0]\n",
    "    for model, fprTpr in fprTprData.items():\n",
    "        ax[0].plot(fprTpr[0], fprTpr[1], label=model)\n",
    "    \n",
    "    rects = ax[1].barh(y=rocAucData.keys(), width=rocAucData.values(), color=colors)\n",
    "    ax[1].set_xlim(0, 100)\n",
    "    ax[1].bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "    ax[1].set_ylabel('AUC score')\n",
    "    ax[1].set_yticklabels('')\n",
    "    ax[1].invert_yaxis()\n",
    "    \n",
    "    fig.legend(handles=rects, labels=models, bbox_to_anchor=(0.09, 0.7, 0.5, 0.5))\n",
    "    \n",
    "    chartsPartTwo = plt.gcf()\n",
    "    \n",
    "    plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_ROC.svg\", format='svg')\n",
    "    plt.close()\n",
    "\n",
    "    #======================================\n",
    "    # Get 5 Fold data\n",
    "    #======================================\n",
    "    nFoldData = {}\n",
    "    \n",
    "    for model, file in variantMetrics.items():\n",
    "        dataPath = '../Data'\n",
    "        df = pd.read_csv(os.path.join(dataPath, file))\n",
    "        cs_scores = df['accuracy']\n",
    "        nFoldData[model] = cs_scores.mean() * 100\n",
    "\n",
    "    #======================================\n",
    "    # Generate chart of 5 Fold data\n",
    "    #======================================\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    rects = ax.bar(nFoldData.keys(), nFoldData.values(), label=nFoldData.keys(), color=getColors(len(nFoldData)))\n",
    "    ax.bar_label(rects, padding=3, fmt='%.2f%%')\n",
    "    \n",
    "    plt.savefig(fname=f\"../Data/{GENE_FILE_VARIANT}_5fold.svg\", format='svg')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"{counter}/{total} - FeatureSet {GENE_FILE_VARIANT} - End\")\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390f8cc-b5aa-4763-a109-4cea4db95e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
